## 1. &nbsp; Motivation: The Importance of Flux Data Standardization and Reproducibility

Collecting and handling eddy covariance data presents challenges on many front, including site and instrument selection, high frequency data processing, and data post-processing and QCQA. While there are many resources online resources that can help with all of these different challenges of eddy covariance measurements (see examples below), here we focus on the approach that the EcoFlux Lab uses for flux data post-processing and QCQA. Here we provide a detailed outline of our procedures for **data post-processing QCQA, gap-filling, and CO2 flux partitioning. We also provide data visualization tools**. We draw on expertise from regional networks and FLUXNET, and leverage widely used tools in the field such as REddyProc and other recently developed machine learning-based gap-filling resources . By following these procedures, you will be able to develop a robust data pipeline to ensure high quality data that you can submit to your regional flux networks. Data standardization and reproducibility helps minimize errors, enhances data reliability, and enables the integration of data sets from diverse ecosystems into global networks like FLUXNET. 

Note that in this pipeline, we are focused on data post-processing, rather than the processing of high frequency (e.g., 20Hz data). While we do provide a link to resources on high frequency flux processing [LINK TO JUNE'S code], this is not within the main scope of this data pipeline. For more information on site set-up, instrument selection, and processing of high frequency data, please contact Xiangmin Sun (xsun130@asu.edu) from the FLUXNET [CH4 and N2O processing committee](https://fluxnet.org/community/fluxnet-working-groups/ch4-and-n2o-processing-committee/)

While the data pipeline described here requires some coding knowledge, the whole pipeline can be run **without having to modify any existing code**. You only need to edit some initialization files, and then execute the code. 

**Additional resources**:

* [Flux Data Post-Processing and QA/QC](https://ameriflux.lbl.gov/resources/resource-list/tools-and-software-for-flux-scientists/flux-data-post-processing-and-qa-qc/)

* [Fluxcourse Educational Materials](https://fluxnet.org/fluxcourse_educational_materials/)

* [Videos on the FLUXNET website](https://fluxnet.org/videos/)

<!-- [Intro section with manifesto on standardization and reproducibility]

- Different techniques/levels of QAQC e.g., with different PIs, software, project needs etc.. These cleaning steps standardize across these different datasets.

Include/emphasize why this is a good way compared with their usual way - same as others (standardized)

[XXX Rosie see notes for adding content here] -->
